{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae5abf87-b06f-4f8c-b448-257f641e3cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Da Silva takes the divine by storm with this unique new novel.  She develops a world unlike any others while keeping it firmly in the real world.  This is a very well written and entertaining novel.  I was quite impressed and intrigued by the way that this solid storyline was developed, bringing the readers right into the world of the story.  I was engaged throughout and definitely enjoyed my time spent reading it.I loved the character development in this novel.  Da Silva creates a cast of high school students who actually act like high school students.  I really appreciated the fact that none of them were thrown into situations far beyond their years, nor did they deal with events as if they had decades of life experience under their belts.  It was very refreshing and added to the realism and impact of the novel.  The friendships between the characters in this novel were also truly touching.Overall, this novel was fantastic.  I can&#8217;t wait to read more and to find out what happens next in the series.  I&#8217;d definitely recommend this debut novel by Da Silva to those who want a little YA fun with a completely unique & shocking storyline.Please note that I received a complimentary copy of this work in exchange for an honest review.\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = './data/sentiment/Books_small.json'\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line) #Con el metodo loads, cargo el review del archivo file, que esta en formato Json, almacenado en un diccionario, con la key='reviewText'\n",
    "        print(review['reviewText'])\n",
    "        print(review['overall'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9086329e-ef28-4478-92ca-bfc8e12f45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = './data/sentiment/Books_small.json'\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line) \n",
    "        reviews.append((review['reviewText'], review['overall'])) #Creo una tupla con los 2 valores que me interesan para entrenar mi modelo\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71bccc-7578-4b88-a62b-9c366550c7ba",
   "metadata": {},
   "source": [
    "Para hacer mas leible y prolijo, y no tener que llamar por indices, sino por atributos, creamos una clase y lo manejamos de esa menera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "de9e704d-ecf0-41f4-8df4-c54f283e8737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#De nuevo, la clase Sentiment, no es necesaria, pero es mas entendible el codigo, y mas prolijo\n",
    "class Sentiment:\n",
    "    NEGATIVE = 'NEGATIVE'\n",
    "    NEUTRAL = 'NEUTRAL'\n",
    "    POSITIVE = 'POSITIVE'\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment() #recibe del metodo get_sentiment, 1,2, negativas 3 neutral, 4 y 5 positicas\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score <=2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score ==3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: # 4 OR 5 STARS\n",
    "            return Sentiment.POSITIVE\n",
    "        \n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews =reviews\n",
    "        \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews)) #filtro, todos los comentarios negativos\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews)) #filtro, todos los comentarios POSITIVOS\n",
    "       # neutral = list(filter(lambda x: x.sentiment == Sentiment.NEUTRAL, self.reviews)) #filtro, todos los comentarios NEUTROS\n",
    "        \n",
    "        positive_adaptado = positive[:len(negative)]# Hago que la cantidad de positivos sea igual a la de negativos\n",
    "        self.reviews =negative + positive_adaptado\n",
    "        random.shuffle(self.reviews) #mezclo bien el orden de los comentarios que uso para entrenar el modelo, sino voy a tener primero los negativos y despues los positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68416a1-973b-4004-8264-a27d17003f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = './data/sentiment/Books_small.json'\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line) \n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "        \n",
    "reviews[5].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d79be9-e93c-41df-97a0-830dfc2c8c49",
   "metadata": {},
   "source": [
    "## Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e196ea2c-48e6-42f7-aa4f-d6d74cada017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42)\n",
    "#33% de las reviews las uso para testeo\n",
    "#66% de los reviews los uso para el entrenamiento\n",
    "\n",
    "train_container = ReviewContainer(training)\n",
    "test_container = ReviewContainer(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125e6dd1-e2f4-425f-a8df-3911a050d11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d48eb33-5ba0-4139-9a15-f20cd5e13915",
   "metadata": {},
   "source": [
    "**Entonces, yo ahora quiero pasarle a mi modelo, un comentario, y quiero que el pueda predecirme, si es positivo o negativo. Entonces, \"x\", lo que voy a pasarle a mi modelo, tiene que ser el texto, y lo que me devuelve \"y\", es la categoria o sentimiento, que es el resultado que quiero 'POSITIVE', 'NEGATIVE', 'NEUTRAL'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d6ccb1de-dee7-42e5-a3c3-6d1a64b892d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n",
      "208\n",
      "208\n"
     ]
    }
   ],
   "source": [
    "train_container.evenly_distribute()\n",
    "\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment()\n",
    "\n",
    "test_container.evenly_distribute()#Separo de manera pareja los comentarios positivos y negativos que voy a usar para entrenar mi modelo\n",
    "\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "#Cuento para asegurarme que tenga la misma cantidad de positivos y negativos\n",
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))\n",
    "print(test_y.count(Sentiment.POSITIVE))\n",
    "print(test_y.count(Sentiment.NEGATIVE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e387d5ed-68ae-4ba0-955a-e2e5d8ff81c3",
   "metadata": {},
   "source": [
    "## Bag of words, VECTORIZACION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3225fe7c-85bf-41f5-9242-2b916222ebc2",
   "metadata": {},
   "source": [
    "Para que el modelo pueda \"leer\", lo que dice el comentario, utilizamos una forma de codificacion de las palabras, a esto lo llamamos, el metodo \"Bag of words\"\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "\"In order to perform machine learning on text documents, we first need to turn the text content into numerical feature vectors...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "03d3b901-2b83-4d79-bc73-e24452f7d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "#vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(train_x)\n",
    "train_x_vectors = vectorizer.transform(train_x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#En el caso de text, no vamos a usar \"fit_transform\", solo queremos transformar, ya que esta es nuestra data de testeo\n",
    "test_x_vectors = vectorizer.transform(test_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e174353-f7a3-4c41-a0a8-f2ffae7c34df",
   "metadata": {},
   "source": [
    "Aca nos devolvio una matriz 2D, donde tiene 670 filas (la cantidad de reviews que usamos para el entrenamiento), y 7372, columnas, posee cada fila.\n",
    "\n",
    "[[0 1 1 1 0 0 1 0 1]\n",
    " [0 2 0 1 0 1 1 0 1]\n",
    " [1 0 0 1 1 0 1 1 1]\n",
    " [0 1 1 1 0 0 1 0 1]]\n",
    " \n",
    " algo parecido a esto, pero mucho mas grande\n",
    " \n",
    " Entonces, esto que tuvimos como resultado, son los reviews, en la forma que vamos a usar para darle a el modelo para que se entrene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "291eb3a4-a083-4d63-9ecc-0f345a5df382",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7086)\t1\n",
      "  (0, 1148)\t1\n",
      "  (0, 350)\t2\n",
      "  (0, 1800)\t1\n",
      "  (0, 6595)\t1\n",
      "  (0, 562)\t1\n",
      "  (0, 3054)\t1\n",
      "  (0, 1558)\t1\n",
      "  (0, 6475)\t1\n",
      "  (0, 6593)\t1\n",
      "  (0, 2895)\t1\n",
      "  (0, 7353)\t1\n",
      "  (0, 539)\t1\n",
      "  (0, 1515)\t1\n",
      "  (0, 5197)\t1\n",
      "  (0, 3545)\t1\n",
      "  (0, 2007)\t1\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.fit_transform(train_x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d959385-fbcb-4f77-87d5-aaf455b04cc6",
   "metadata": {},
   "source": [
    "**Ahora tengo que elegir el modelo que voy a utilizar**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b594d131-529f-40ab-a1f8-8e614411ac26",
   "metadata": {},
   "source": [
    "## Clasification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c6694e-d47a-4b9c-b539-c2edb1d8ad21",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "    \n",
    "Para saber el modelo o clasificador (classifier) correcto a utilizar, hay que ver https://www.youtube.com/watch?v=_PwhiWxHK8o , o ver videos en internet o articulos a ver cual recomiendan para cada situacion. Tambien ver como se comporta cada modelo y cual se adapta mejor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ccfcd0-62cc-4e1d-81d5-afdc2c7220b6",
   "metadata": {},
   "source": [
    "#### LINEAR SVM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bf934321-a41f-4477-a9cb-48cea4174a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEGATIVE']\n",
      "This book was really horrible. It's twilight but with mers. If you want a mer book read everblue it's better.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel ='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "#Ahora con el SVM LINEAR MODEL, predecimos el comentario, a partir de lo que aprendio el modelo\n",
    "svmPrediction = clf_svm.predict(test_x_vectors[0])\n",
    "\n",
    "print(svmPrediction)\n",
    "print(test_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd1718-6108-4f38-b223-794bd1b4b1d2",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "88efad7c-ad4a-4241-b485-b3f0f661ff5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POSITIVE']\n",
      "This book was really horrible. It's twilight but with mers. If you want a mer book read everblue it's better.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "treePrediction = clf_dec.predict(test_x_vectors[0])\n",
    "\n",
    "print(treePrediction)\n",
    "print(test_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacda877-60a6-4da5-8918-ff3db373f8a6",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "84dba524-70bb-4f65-a6fd-d1cb0aa7f843",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEGATIVE']\n",
      "This book was really horrible. It's twilight but with mers. If you want a mer book read everblue it's better.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf_gnb = MultinomialNB()\n",
    "#\"TypeError: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.\", try using MultinomialNB instead. You can't use vectorized array with GuassianNB.\n",
    "#Aqui, no podemos usar GaussianNB(), por lo dicho arriba\n",
    "\n",
    "clf_gnb.fit(train_x_vectors, train_y)\n",
    "\n",
    "\n",
    "naiveBayesPrediction = clf_gnb.predict(test_x_vectors[0])\n",
    "\n",
    "print(naiveBayesPrediction)\n",
    "print(test_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac193d3-4797-4d66-8e3a-47d49388d9e5",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e1f3509c-3188-4285-b999-cdd1b13232a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POSITIVE']\n",
      "This book was really horrible. It's twilight but with mers. If you want a mer book read everblue it's better.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression(random_state=0).fit(train_x_vectors, train_y)\n",
    "\n",
    "logPrediction = clf_log.predict(test_x_vectors[0])\n",
    "\n",
    "print(treePrediction)\n",
    "print(test_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c65462-030d-4cdc-9cb5-de9ecffd1e22",
   "metadata": {},
   "source": [
    "## EVALUATION OF MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2000a7-e98b-4234-ae80-cfa69f0c1b1f",
   "metadata": {},
   "source": [
    "Ahora que entrenamos todos nuestros modelos, vamos a evaluarlos, con todos los valores, a ver como se comportan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "139229cd-aae9-4ad9-a451-84b2fa6b4eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8124242424242424\n",
      "0.7666666666666667\n",
      "0.8369696969696969\n",
      "0.8409090909090909\n"
     ]
    }
   ],
   "source": [
    "#MEAN ACCURACY\n",
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "print(clf_gnb.score(test_x_vectors, test_y))\n",
    "print(clf_log.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "95e57ca2-2947-46f3-9006-4abf4e34a372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7124242424242424\n",
      "0.6227272727272727\n",
      "0.6796969696969697\n",
      "0.7448484848484849\n"
     ]
    }
   ],
   "source": [
    "#MEAN ACCURACY (2da ejecucion, despues de igualar la cantidad de comentarios negativos con positivos)\n",
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "print(clf_gnb.score(test_x_vectors, test_y))\n",
    "print(clf_log.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de4f5ac1-9b16-4234-93d7-3ce739e21f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91319444 0.21052632 0.22222222]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0591cd69-896d-4a60-a680-51ba261b315f",
   "metadata": {},
   "source": [
    "Con este ensayo, podemos concluir que el modelo es bueno para predecir comentarios positivos, pero es muy malo para comentarios negativos o neutros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "073f4a87-d564-447d-9dfc-656160bf4ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora, ensayo todos a ver como se comportan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0ca7688-450c-4ba7-a0d2-86b248b3154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85309735 0.0952381  0.        ]\n",
      "[0.9233279 0.        0.       ]\n",
      "[0.91370558 0.12244898 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(test_y, clf_dec.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_gnb.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_log.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904991d7-cbbb-44d7-87cc-b8d863251a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a9f0e93-3189-4196-93d8-cb2cb0c758f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "Bueno, ahora quiero mejorar mi modelo para NEUTRAL and NEGATIVE.\n",
    "\n",
    "Para eso, lo primero que debemos revisar, es la data que le estamos dando al modelo para que se entrene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18fb3b85-aaa6-4da5-88a6-0e64469b66b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5611\n",
      "436\n",
      "653\n"
     ]
    }
   ],
   "source": [
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))\n",
    "print(train_y.count(Sentiment.NEUTRAL))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d62a40-3405-4d9b-9637-a18edfc595e2",
   "metadata": {},
   "source": [
    "552 de 670 comentarios, son POSITIVE, y negativos, solo 47, entonces, debemos balancear la data, entre los tipos de cometarios\n",
    "\n",
    "Vamos a cargar un dataset mas grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a7c3b77-6fcc-48e4-8501-8a4451feae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = './data/sentiment/Books_small_10000.json'\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line) \n",
    "        reviews.append(Review(review['reviewText'], review['overall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ea834-8900-4be4-9aef-13e173053b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PODEMOS VER QUE LA MUESTRA AUMENTO\n",
    "\n",
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))\n",
    "print(train_y.count(Sentiment.NEUTRAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1ac6f7b-c138-473f-a33d-0cc9e181dca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90738061 0.2656     0.40268456]\n",
      "[0.87186778 0.14789916 0.17460317]\n",
      "[0.91276279 0.0286533  0.        ]\n",
      "[0.92139968 0.29250457 0.40983607]\n"
     ]
    }
   ],
   "source": [
    "#2da ejecucion, poniendo una muestra mas grande\n",
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_dec.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_gnb.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_log.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b52c1e5-3250-481d-bc16-3b9e8c99419e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91f31afa-6a3d-4d49-ad58-d8cca0b4071c",
   "metadata": {},
   "source": [
    "Creo la clase ReviewContainer, para contener a nuestra data, y manejarla mejor, yo ahora lo que quiero es nivelar mi muestra, para entrenarla mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "32e9d82e-9a0e-4ff6-bb8c-c7565bc35e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85363477 0.         0.28146853]\n",
      "[0.78271504 0.         0.19722425]\n",
      "[0.83624543 0.         0.27346637]\n",
      "[0.8783008  0.         0.31077216]\n"
     ]
    }
   ],
   "source": [
    "#(3era ejecucion, despues de igualar la cantidad de comentarios negativos con positivos)\n",
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_dec.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_gnb.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_log.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bacab5-531c-43ad-94c3-6edd50f92f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5e2d6f7-ba3f-40f4-a8a9-0d8edb027143",
   "metadata": {},
   "source": [
    "### Ahora, tambien distribuyo de manera equilibrada la data que destino al entrenamiento de mi modelo, a ver que resultados obtengo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d0c58fd0-ec02-4571-b936-7edfec1d1f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980769230769231\n",
      "0.6370192307692307\n",
      "0.7980769230769231\n",
      "0.8149038461538461\n"
     ]
    }
   ],
   "source": [
    "#MEAN ACCURACY (3ra ejecucion)\n",
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "print(clf_gnb.score(test_x_vectors, test_y))\n",
    "print(clf_log.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c3610ebc-e96b-4351-8536-dad6b6cd1cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8028169  0.         0.79310345]\n",
      "[0.63614458 0.         0.63788969]\n",
      "[0.77777778 0.         0.81497797]\n",
      "[0.82051282 0.         0.808933  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1492: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Charl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1492: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Charl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1492: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Charl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1492: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n"
     ]
    }
   ],
   "source": [
    "#(4ta ejecucion)\n",
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_dec.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_gnb.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_log.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4897ed2-d9fe-417f-b874-3bda156415fb",
   "metadata": {},
   "source": [
    "Conclusion: Se puede obsevar como mejore notablemente el F1 SCORE, al equilibrar la muestra\n",
    "\n",
    "nota: los nuetrales, los sacamos, para simplificar el ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28e3fe-1b4d-4416-9d50-39df9f6e57bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10b0eeb2-ae02-48e3-8ed5-78c6172454e2",
   "metadata": {},
   "source": [
    "## Ahora vamos a ver nuestro modelo en accion, con un test QUALITATIVO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "78ec6fc8-62d5-422b-93ff-464f4fb48796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = [\"Very good\", \"I'm not sure what to say about this book. Interesting plot idea but poorly executed. I finished it and it wasn't the worst book ever but isn't something I would recommend to anyone. And not worth the $2.99 I paid for it.  Also needs some serious editing.\"]\n",
    "new_test = vectorizer.transform(test_set)\n",
    "\n",
    "clf_svm.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c094c0d-1fa2-4316-b284-37493613ea7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7fc7b0b-80ba-4d69-af44-8c9be9c4c6a5",
   "metadata": {},
   "source": [
    "Ahora si quiero mejorar aun mas mi modelo podria utilizar en vez de CountVectorizer,TfidfVectorizer , que cuenta las palabras \"sentimentales\", las que le ponen mas peso a la review, lo cual mejora la performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411a99ec-c5fc-4273-b4db-5ea3cafd871b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "68f89909-7f8f-4598-9cbf-33bdf5ba0c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076923076923077\n",
      "0.6346153846153846\n",
      "0.8125\n",
      "0.8052884615384616\n"
     ]
    }
   ],
   "source": [
    "#MEAN ACCURACY (4ta ejecucion)\n",
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "print(clf_gnb.score(test_x_vectors, test_y))\n",
    "print(clf_log.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "35bff0a7-8f17-4ca6-8cd4-cf488ae12365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80582524 0.         0.80952381]\n",
      "[0.62189055 0.         0.64651163]\n",
      "[0.79144385 0.         0.82969432]\n",
      "[0.80291971 0.         0.80760095]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1492: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Charl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1492: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Charl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1492: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "C:\\Users\\Charl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1492: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_dec.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_gnb.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_log.predict(test_x_vectors), average = None, labels =[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcd1da9-9d3f-4ea4-8316-f168fbc143a5",
   "metadata": {},
   "source": [
    "***Aca podemos observar que en algunos modelos, me ayudo a mejorar la performance, mientras otros, la empeoro. Por ejemplo mejoro LINEAR SVM MODEL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69eff5-ab22-4063-ac04-3396a5b055fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e489f-315e-4b78-862e-a4d93e5182ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ffdf43b0-2acd-4536-ace6-66615a6609d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Busco mejorar aun mas mis modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf44af-e86e-4e54-b413-03ab2df2efc5",
   "metadata": {},
   "source": [
    "## Turning our model (with Grid Search)\n",
    "https://www.mygreatlearning.com/blog/gridsearchcv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a58f3e0a-2661-428a-9b80-73787a8a98dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': (1, 4, 8, 16, 32), 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':('linear','rbf'), 'C':(1,4,8,16,32)} #Valores que pruebo para C, a ver cual me da mejor performance                           \n",
    "\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(train_x_vectors, train_y) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f60d02a-7310-4aad-a2b9-4f2db4fbad8c",
   "metadata": {},
   "source": [
    "#### *Otra mejora, que puedo aplicar, antes de usar GridSearchCV, para mejorar mis parametros, del modelo, es filtrar, los signos de exclamacion, ya que el metodo, cuenta como si fueran dos palabras distintas good! y good*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a4794-ce41-4d2f-9083-5dc74e2e4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "por ahora lo dejaremos hasta aqui, pero se puede seguir mejorando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd2c8b-6aef-4230-802b-6aff2f49923b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98850885-6a6e-4599-8971-5bc872426477",
   "metadata": {},
   "source": [
    "## SAVING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ac0b9cfb-a5ad-4fe6-bc7b-ee0055bb01f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora queremos grabarlo, para no tener que reentrenarlo ,cada vez que querramos usarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "55064931-8925-4ca9-a976-b98858da18b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./modelos2021/sentiment_classifier.pkl','wb') as f:\n",
    "    pickle.dump(clf,f)\n",
    "#Grabamos, todos los parametros que tenemos en clf, en el archivo sentiment_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421f2db7-f72c-4b8e-ab58-92a5f170ab88",
   "metadata": {},
   "source": [
    "## LOADING THE MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "073b5e4a-f97c-496f-9e6e-f10c290343d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora veamos nuestro modelo grabado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cdf2ac0a-0e08-4574-86f8-0b8478c1401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./modelos2021/sentiment_classifier.pkl','rb') as f:\n",
    "    loaded_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "30fc9753-a1fe-4388-b415-0a037e27e5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This book was really horrible. It's twilight but with mers. If you want a mer book read everblue it's better.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_x[0])\n",
    "\n",
    "loaded_clf.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00330d15-2e1a-4fda-9d39-add809c31b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
